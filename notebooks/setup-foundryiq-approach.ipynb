{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a663899b",
   "metadata": {},
   "source": [
    "# SharePoint FoundryIQ Setup (Agentic Retrieval)\n",
    "\n",
    "This notebook sets up the **FoundryIQ / Agentic Retrieval** approach using `RemoteSharePointKnowledgeSource`.\n",
    "\n",
    "Instead of building an index pipeline, this approach uses a **Knowledge Base** that connects directly to SharePoint via the [Copilot Retrieval API](https://learn.microsoft.com/en-us/microsoft-365-copilot/extensibility/api/ai-services/retrieval/overview).\n",
    "\n",
    "**Pipeline**: Knowledge Source → Knowledge Base → Retrieve\n",
    "\n",
    "**Reference**: [Create a remote SharePoint knowledge source](https://learn.microsoft.com/en-us/azure/search/agentic-knowledge-source-how-to-sharepoint-remote?pivots=python)\n",
    "\n",
    "### Key Differences from Indexer Approach\n",
    "\n",
    "| Feature | Indexer (Notebook 1) | FoundryIQ (This notebook) |\n",
    "|---------|---------------------|---------------------------|\n",
    "| Index needed | Yes (you build it) | No (handled by Copilot API) |\n",
    "| Cross-tenant | Supported | Same-tenant only |\n",
    "| Auth | App permissions | User identity (delegated) |\n",
    "| Rate limit | Standard Search limits | 200 req/user/hour |\n",
    "| Chat model | Not required | Required (gpt-4o / gpt-4.1 / gpt-5) |\n",
    "| Security trimming | ACL fields in index | Automatic (user's access) |\n",
    "| Licensing | Azure AI Search only | **Microsoft 365 Copilot license required** |\n",
    "\n",
    "> **Prerequisites**:\n",
    "> - Azure AI Search (Basic+) with [semantic ranker enabled](https://learn.microsoft.com/en-us/azure/search/semantic-how-to-enable-disable)\n",
    "> - Azure OpenAI with a supported chat model deployed (`gpt-4o`, `gpt-4o-mini`, `gpt-4.1`, `gpt-4.1-mini`, `gpt-4.1-nano`, `gpt-5`, `gpt-5-mini`, `gpt-5-nano`)\n",
    "> - Azure & Microsoft 365 must be in the **same Entra ID tenant**\n",
    "> - **Microsoft 365 Copilot license** (usage is billed through M365)\n",
    "> - SharePoint site accessible to the querying user\n",
    "> - `az` CLI installed and logged in (for user identity token)\n",
    "> - Copy `.env.template` to `.env` in this `notebooks/` folder and fill in values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807cc8f4",
   "metadata": {},
   "source": [
    "## Step 0: Configuration\n",
    "\n",
    "Loads values from `notebooks/.env` (same folder as this notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d20c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import subprocess\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env from the same directory as this notebook\n",
    "load_dotenv()\n",
    "\n",
    "# Azure AI Search\n",
    "SEARCH_URL = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "SEARCH_API_KEY = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "API_VERSION = os.getenv(\"AZURE_SEARCH_API_VERSION\", \"2025-11-01-preview\")\n",
    "\n",
    "# Azure OpenAI (chat model for query planning)\n",
    "AOAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AOAI_CHAT_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\", \"gpt-4o\")\n",
    "\n",
    "# SharePoint\n",
    "SPO_ENDPOINT = os.getenv(\"SPO_ENDPOINT\")\n",
    "SPO_TENANT_ID = os.getenv(\"SPO_TENANT_ID\")\n",
    "\n",
    "# Common headers\n",
    "HEADERS = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"api-key\": SEARCH_API_KEY\n",
    "}\n",
    "\n",
    "# Resource names\n",
    "KNOWLEDGE_SOURCE_NAME = \"sharepoint-knowledge-source\"\n",
    "KNOWLEDGE_BASE_NAME = \"sharepoint-knowledge-base\"\n",
    "\n",
    "# Validate\n",
    "missing = [v for v in [\"AZURE_SEARCH_ENDPOINT\", \"AZURE_SEARCH_ADMIN_KEY\",\n",
    "                        \"AZURE_OPENAI_ENDPOINT\", \"SPO_ENDPOINT\", \"SPO_TENANT_ID\"] if not os.getenv(v)]\n",
    "if missing:\n",
    "    print(f\"\\u274c Missing env vars: {', '.join(missing)}\")\n",
    "    print(\"   Copy .env.template to .env and fill in values.\")\n",
    "else:\n",
    "    print(f\"Search endpoint:  {SEARCH_URL}\")\n",
    "    print(f\"OpenAI endpoint:  {AOAI_ENDPOINT}\")\n",
    "    print(f\"Chat deployment:  {AOAI_CHAT_DEPLOYMENT}\")\n",
    "    print(f\"SharePoint site:  {SPO_ENDPOINT}\")\n",
    "    print(\"Configuration loaded \\u2713\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dfe5d7",
   "metadata": {},
   "source": [
    "### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d244f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_search_api(method, path, body=None, extra_headers=None, expected_status=None):\n",
    "    \"\"\"Make a call to Azure AI Search REST API.\"\"\"\n",
    "    url = f\"{SEARCH_URL}/{path}\"\n",
    "    params = {\"api-version\": API_VERSION}\n",
    "    headers = {**HEADERS, **(extra_headers or {})}\n",
    "\n",
    "    response = requests.request(method, url, headers=headers, params=params, json=body)\n",
    "\n",
    "    status = response.status_code\n",
    "    if expected_status and status not in expected_status:\n",
    "        print(f\"\\u274c {method} {path} \\u2192 HTTP {status}\")\n",
    "        print(response.text)\n",
    "        return None\n",
    "\n",
    "    print(f\"\\u2713 {method} {path} \\u2192 HTTP {status}\")\n",
    "    if response.text:\n",
    "        try:\n",
    "            return response.json()\n",
    "        except ValueError:\n",
    "            return response.text\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ba4f6a",
   "metadata": {},
   "source": [
    "## Step 1: Create Knowledge Source\n",
    "\n",
    "A `RemoteSharePointKnowledgeSource` connects to SharePoint at **query time** via the Copilot Retrieval API.\n",
    "\n",
    "Unlike the indexer approach, **no data is copied** and no site URL is configured at creation — the user's identity token at query time determines which SharePoint content is accessible.\n",
    "\n",
    "> The Azure subscription and the SharePoint site **must be in the same Entra ID tenant**.\n",
    "\n",
    "### Optional parameters (`remoteSharePointParameters`)\n",
    "- `containerTypeId` — for SharePoint Embedded connections (omit for standard SharePoint Online)\n",
    "- `filterExpression` — [KQL expression](https://learn.microsoft.com/en-us/sharepoint/dev/general-development/keyword-query-language-kql-syntax-reference) to scope retrieval at definition time\n",
    "- `resourceMetadata` — metadata fields to return with results (e.g., `Author`, `Title`, `LastModifiedTime`)\n",
    "\n",
    "### Filter expression examples\n",
    "\n",
    "| Scenario | Expression |\n",
    "|----------|-----------|\n",
    "| Filter to a single site by ID | `SiteID:\"00aa00aa-bb11-cc22-dd33-44ee44ee44ee\"` |\n",
    "| Filter to files under a path | `Path:\"https://contoso.sharepoint.com/sites/mysite/Shared Documents/en/mydocs\"` |\n",
    "| Filter by file type | `FileExtension:\"docx\" OR FileExtension:\"pdf\" OR FileExtension:\"pptx\"` |\n",
    "| Filter by date range | `LastModifiedTime >= 2024-07-22 AND LastModifiedTime <= 2025-01-08` |\n",
    "| Filter by sensitivity label | `InformationProtectionLabelId:\"f0ddcc93-d3c0-4993-b5cc-76b0a283e252\"` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7176537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_source_body = {\n",
    "    \"name\": KNOWLEDGE_SOURCE_NAME,\n",
    "    \"kind\": \"remoteSharePoint\",\n",
    "    # remoteSharePointParameters is optional for standard SharePoint Online.\n",
    "    # Uncomment below to add KQL filtering or metadata fields:\n",
    "    # \"remoteSharePointParameters\": {\n",
    "    #     \"filterExpression\": \"FileType:docx OR FileType:pdf\",\n",
    "    #     \"resourceMetadata\": [\"Author\", \"LastModifiedTime\"]\n",
    "    # }\n",
    "}\n",
    "\n",
    "result = call_search_api(\"POST\", \"knowledgesources\", knowledge_source_body, expected_status=[201])\n",
    "if result:\n",
    "    print(f\"\\nKnowledge source '{KNOWLEDGE_SOURCE_NAME}' created.\")\n",
    "    print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ba1b5d",
   "metadata": {},
   "source": [
    "## Step 2: Create Knowledge Base\n",
    "\n",
    "A Knowledge Base ties together:\n",
    "- The knowledge source (SharePoint)\n",
    "- An AI model for **query planning** (gpt-4o or gpt-4.1)\n",
    "\n",
    "The model decomposes user queries into sub-queries for retrieval.\n",
    "\n",
    "Uses `PUT` (create-or-update) so it's idempotent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f57e7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_base_body = {\n",
    "    \"name\": KNOWLEDGE_BASE_NAME,\n",
    "    \"description\": \"SharePoint knowledge base for policy documents\",\n",
    "    \"knowledgeSources\": [\n",
    "        {\"name\": KNOWLEDGE_SOURCE_NAME}\n",
    "    ],\n",
    "    \"models\": [\n",
    "        {\n",
    "            \"kind\": \"azureOpenAI\",\n",
    "            \"azureOpenAIParameters\": {\n",
    "                \"resourceUri\": AOAI_ENDPOINT,\n",
    "                \"deploymentId\": AOAI_CHAT_DEPLOYMENT,\n",
    "                \"modelName\": AOAI_CHAT_DEPLOYMENT   # e.g. \"gpt-4o\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Note: PUT URL uses knowledgebases('name') format; Prefer header is required\n",
    "result = call_search_api(\n",
    "    \"PUT\",\n",
    "    f\"knowledgebases('{KNOWLEDGE_BASE_NAME}')\",\n",
    "    knowledge_base_body,\n",
    "    extra_headers={\"Prefer\": \"return=representation\"},\n",
    "    expected_status=[200, 201]\n",
    ")\n",
    "if result:\n",
    "    print(f\"\\nKnowledge base '{KNOWLEDGE_BASE_NAME}' created/updated.\")\n",
    "    print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7823d4",
   "metadata": {},
   "source": [
    "## Step 3: Get User Identity Token\n",
    "\n",
    "FoundryIQ queries SharePoint **on behalf of the user**. Two separate auth mechanisms are needed:\n",
    "\n",
    "1. **`api-key` header** → authenticates to Azure AI Search (already configured in Step 0)\n",
    "2. **`x-ms-query-source-authorization` header** → user identity token passed raw (no `Bearer` prefix)\n",
    "\n",
    "The source authorization token must be scoped for **Azure AI Search** (`https://search.azure.com/.default`), as documented in the [remote SharePoint knowledge source](https://learn.microsoft.com/en-us/azure/search/agentic-knowledge-source-how-to-sharepoint-remote) guide. Azure AI Search then uses this token to call the Copilot Retrieval API on your behalf.\n",
    "\n",
    "> Make sure you're logged in: `az login`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422eac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_token(scope=\"https://search.azure.com/.default\"):\n",
    "    \"\"\"Get a user identity token scoped for Azure AI Search (used for SharePoint access).\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"az\", \"account\", \"get-access-token\",\n",
    "             \"--scope\", scope,\n",
    "             \"--query\", \"accessToken\", \"-o\", \"tsv\"],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=True\n",
    "        )\n",
    "        token = result.stdout.strip()\n",
    "        print(f\"\\u2713 Token obtained for scope: {scope}\")\n",
    "        print(f\"  Token length: {len(token)} chars\")\n",
    "        return token\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"\\u274c Failed to get token. Run 'az login' first.\")\n",
    "        print(e.stderr)\n",
    "        return None\n",
    "\n",
    "# Token scoped for Azure AI Search (Search service uses it to call Copilot Retrieval API on your behalf)\n",
    "USER_TOKEN = get_user_token(\"https://search.azure.com/.default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21ea7dd",
   "metadata": {},
   "source": [
    "## Step 4: Query the Knowledge Base\n",
    "\n",
    "The [`retrieve` action](https://learn.microsoft.com/en-us/azure/search/agentic-retrieval-how-to-retrieve) queries SharePoint through the knowledge base.\n",
    "\n",
    "Key points:\n",
    "- `x-ms-query-source-authorization` header carries the user identity token (raw JWT, no `Bearer` prefix)\n",
    "- Results are automatically filtered by the user's SharePoint permissions\n",
    "- The chat model decomposes your query into sub-queries for better retrieval\n",
    "- Rate limited to **200 requests/user/hour** (Copilot Retrieval API limit)\n",
    "- Query character limit: **1,500 characters**\n",
    "- Maximum **25 results** per knowledge source per query\n",
    "- Use `knowledgeSourceParams` to pass runtime overrides (e.g., `filterExpressionAddOn` for query-time KQL filters)\n",
    "\n",
    "> **Tip**: Queries about the *content* of documents work best. Queries about file locations or dates should use `filterExpressionAddOn` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c457d18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_QUERY = \"What are the company travel expense policies?\"  # Change this to your query\n",
    "\n",
    "if not USER_TOKEN:\n",
    "    print(\"\\u274c No user token. Run Step 3 first.\")\n",
    "else:\n",
    "    retrieve_body = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": SEARCH_QUERY\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"includeActivity\": True,\n",
    "        # Optional: override knowledge source settings at query time\n",
    "        \"knowledgeSourceParams\": [\n",
    "            {\n",
    "                \"knowledgeSourceName\": KNOWLEDGE_SOURCE_NAME,\n",
    "                \"kind\": \"remoteSharePoint\",\n",
    "                \"includeReferences\": True,\n",
    "                \"includeReferenceSourceData\": True,\n",
    "                # Optional: add a KQL filter at query time (AND'd with knowledge source filter)\n",
    "                # \"filterExpressionAddOn\": \"FileExtension:\\\"docx\\\"\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    result = call_search_api(\n",
    "        \"POST\",\n",
    "        f\"knowledgebases('{KNOWLEDGE_BASE_NAME}')/retrieve\",\n",
    "        retrieve_body,\n",
    "        extra_headers={\n",
    "            \"x-ms-query-source-authorization\": USER_TOKEN   # raw JWT, no \"Bearer \" prefix\n",
    "        },\n",
    "        expected_status=[200, 206]\n",
    "    )\n",
    "\n",
    "    if result:\n",
    "        # Display response messages\n",
    "        print(\"=== Answer ===\")\n",
    "        for msg in result.get(\"response\", []):\n",
    "            for part in msg.get(\"content\", []):\n",
    "                text = part.get(\"text\", \"\")\n",
    "                print(text[:2000])\n",
    "\n",
    "        # Display references\n",
    "        refs = result.get(\"references\", [])\n",
    "        if refs:\n",
    "            print(f\"\\n--- {len(refs)} Reference(s) ---\")\n",
    "            for i, ref in enumerate(refs, 1):\n",
    "                url = ref.get('webUrl', ref.get('docKey', 'N/A'))\n",
    "                score = ref.get('rerankerScore', '')\n",
    "                label = ref.get('searchSensitivityLabelInfo', {})\n",
    "                label_name = f\" [{label.get('displayName')}]\" if label.get('displayName') else \"\"\n",
    "                print(f\"  {i}. [{ref.get('type')}] {url} (score: {score}){label_name}\")\n",
    "\n",
    "        # Display activity summary (including errors)\n",
    "        activity = result.get(\"activity\", [])\n",
    "        if activity:\n",
    "            print(f\"\\n--- Activity ({len(activity)} steps) ---\")\n",
    "            for a in activity:\n",
    "                elapsed = a.get('elapsedMs', '?')\n",
    "                atype = a.get('type')\n",
    "                extra = \"\"\n",
    "                if 'inputTokens' in a:\n",
    "                    extra = f\" (in: {a['inputTokens']}, out: {a.get('outputTokens', '?')})\"\n",
    "                if 'count' in a:\n",
    "                    extra = f\" ({a['count']} results)\"\n",
    "                print(f\"  {atype}: {elapsed}ms{extra}\")\n",
    "                if 'error' in a:\n",
    "                    print(f\"    \\u274c Error: {json.dumps(a['error'], indent=4)}\")\n",
    "    else:\n",
    "        print(\"\\u274c No result returned. Check the error output above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46766a5e",
   "metadata": {},
   "source": [
    "## Step 5: List Knowledge Sources & Knowledge Bases\n",
    "\n",
    "Verify your resources were created successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7065e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Knowledge Sources ===\")\n",
    "result = call_search_api(\"GET\", \"knowledgesources\", expected_status=[200])\n",
    "if result:\n",
    "    for ks in result.get(\"value\", []):\n",
    "        print(f\"  - {ks.get('name')} ({ks.get('kind')})\")\n",
    "\n",
    "print(\"\\n=== Knowledge Bases ===\")\n",
    "result = call_search_api(\"GET\", \"knowledgebases\", expected_status=[200])\n",
    "if result:\n",
    "    for kb in result.get(\"value\", []):\n",
    "        print(f\"  - {kb.get('name')}: {kb.get('description', '')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5da9e60",
   "metadata": {},
   "source": [
    "## Cleanup (Optional)\n",
    "\n",
    "Delete the knowledge base and knowledge source. Since no index was created, there's nothing else to clean up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b00f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to delete all resources\n",
    "# call_search_api(\"DELETE\", f\"knowledgebases('{KNOWLEDGE_BASE_NAME}')\", expected_status=[204, 404])\n",
    "# call_search_api(\"DELETE\", f\"knowledgesources('{KNOWLEDGE_SOURCE_NAME}')\", expected_status=[204, 404])\n",
    "# print(\"All resources deleted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae117217",
   "metadata": {},
   "source": [
    "## Limitations & Notes\n",
    "\n",
    "### Licensing\n",
    "- **Microsoft 365 Copilot license** is required — usage is billed through M365\n",
    "- Without a Copilot license, retrieve calls will return errors\n",
    "\n",
    "### Tenant & Identity\n",
    "- **Same-tenant only**: Azure subscription and M365 must share the same Entra ID tenant\n",
    "- **User identity**: Each query runs with the calling user's SharePoint permissions\n",
    "- No support for Copilot connectors or OneDrive content — only SharePoint sites\n",
    "\n",
    "### Query Limits ([Copilot Retrieval API](https://learn.microsoft.com/en-us/microsoft-365-copilot/extensibility/api/ai-services/retrieval/overview))\n",
    "- **200 requests** per user per hour\n",
    "- **1,500 character** query limit\n",
    "- Maximum **25 results** from a single query\n",
    "- Hybrid queries only supported for: `.doc`, `.docx`, `.pptx`, `.pdf`, `.aspx`, `.one`\n",
    "- Multimodal retrieval (tables, images, charts) is **not supported**\n",
    "- Invalid KQL filter expressions are silently ignored\n",
    "- Results from Copilot Retrieval API are returned **unordered** (reranking is done by Azure AI Search)\n",
    "\n",
    "### Model & Search\n",
    "- **Chat model required**: `gpt-4o`, `gpt-4o-mini`, `gpt-4.1`, `gpt-4.1-mini`, `gpt-4.1-nano`, `gpt-5`, `gpt-5-mini`, `gpt-5-nano`\n",
    "- **No custom embeddings**: Unlike the indexer approach, you can't customize chunking or vector dimensions\n",
    "- **Preview API**: This feature uses `2025-11-01-preview` and may change"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
